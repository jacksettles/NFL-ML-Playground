{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecce0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d272f4",
   "metadata": {},
   "source": [
    "# Read in data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2e367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFL = pd.read_csv(r\"NFL Play by Play 2009-2018 (v5).csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a569b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Filter rows '''\n",
    "NFL = NFL[(NFL.down.isin([1, 2, 3, 4])) & ((NFL.play_type == 'run') | (NFL.play_type == 'pass'))\n",
    "          & (NFL.incomplete_pass == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b216d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFL = NFL[['game_id', 'posteam', 'posteam_type', 'defteam', 'game_seconds_remaining', 'yardline_100', 'down', 'ydstogo', 'yards_gained', 'score_differential',\n",
    "           'play_type', 'pass_length', 'pass_location', 'run_location', 'run_gap', 'shotgun', 'no_huddle']]\n",
    "NFL.dropna(subset=['yards_gained'], inplace=True)\n",
    "NFL.dropna(subset=['game_seconds_remaining'], inplace=True)\n",
    "NFL['game_seconds_remaining'] = NFL['game_seconds_remaining'].astype(int)\n",
    "NFL['yards_gained'] = NFL['yards_gained'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6b41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_play(play):\n",
    "    play_type, pass_length, pass_location, run_location, run_gap = play\n",
    "    if play_type == 'pass':\n",
    "        if (pass_length != 'unknown') & (pass_location != 'unknown'):\n",
    "            return play_type.capitalize() + \" \" + pass_length.capitalize() + \" \" + pass_location.capitalize()\n",
    "    elif play_type == 'run':\n",
    "        if run_location == 'middle':\n",
    "            return \"Run Middle\"\n",
    "        elif (run_location != 'unknown') & (run_gap != 'unknown'):\n",
    "            return \"Run \" + run_location.capitalize() + \" \" + run_gap.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1e7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sit is situation\n",
    "# Down, yards to go, and yards gained gets fed in to determine play success (1), which is defined below\n",
    "def play_success(sit):\n",
    "    down, ydstogo, yards_gained = sit\n",
    "    if down == 1:\n",
    "        if (yards_gained/ydstogo) >= 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif down == 2:\n",
    "        if (yards_gained/ydstogo) >= 0.7:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if (yards_gained/ydstogo) >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5335d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Turn unknown values into \"unknown\" '''\n",
    "NFL = NFL.replace(np.nan, 'unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f54bf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create column in DF for complete play type '''\n",
    "NFL['complete_play'] = NFL[['play_type', 'pass_length', 'pass_location', 'run_location', 'run_gap']].apply(get_play, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2871f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = NFL.groupby('complete_play').count()[['play_type']]\n",
    "# print(cp)\n",
    "\n",
    "''' Get the sum of all the plays '''\n",
    "total = 0\n",
    "for x in cp['play_type']:\n",
    "    total += x\n",
    "\n",
    "''' Turn each value into a percentage of the sum '''\n",
    "for i, row in cp.iterrows():\n",
    "    cp.at[i, 'play_type'] *= 100 / total\n",
    "    \n",
    "# print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3284b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFL['complete_play'] = NFL['complete_play'].replace('', np.nan, regex=True)\n",
    "NFL.dropna(subset=['complete_play'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a40f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create column for successful plays '''\n",
    "NFL['play_success'] = NFL[['down', 'ydstogo', 'yards_gained']].apply(play_success, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dbf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Labeling play types to numerical values\n",
    "    Pass Deep Left->0\n",
    "    Pass Deep Middle->1\n",
    "    Pass Deep Right->2\n",
    "    Pass Short Left->3\n",
    "    Pass Short Middle->4\n",
    "    Pass Short Right->5\n",
    "    Run Left End->6\n",
    "    Run Left Guard->7\n",
    "    Run Left Tackle->8\n",
    "    Run Middle->9\n",
    "    Run Right End->10\n",
    "    Run Right Guard->11\n",
    "    Run Right Tackle->12 '''\n",
    "encoder = LabelEncoder()\n",
    "NFL['cp_label'] = encoder.fit_transform(NFL['complete_play'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f558b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Yardage to go is binned'''\n",
    "def yardage_bin(y):\n",
    "    if y <= 5:\n",
    "        return 0\n",
    "    elif (y > 5) & (y <= 9):\n",
    "        return 1\n",
    "    elif (y > 9) & (y <= 15):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856704d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Score differential is binned\n",
    "The value equivalent to the number of possesions\n",
    "the posessing team is winning or losing by'''\n",
    "def score_diff_bin(x):\n",
    "    if x < 0:\n",
    "        if x <= -25:\n",
    "            return -4\n",
    "        elif (x > -25) & (x <= -17):\n",
    "            return -3\n",
    "        elif (x > -17) & (x <= -9):\n",
    "            return -2\n",
    "        elif x > -9:\n",
    "            return -1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    elif x > 0:\n",
    "        if x < 9:\n",
    "            return 1\n",
    "        elif (x >= 9) & (x < 17):\n",
    "            return 2\n",
    "        elif (x >= 17) & (x < 25):\n",
    "            return 3\n",
    "        elif x >= 25:\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3afbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Replace the ydstogo values with their bin numbers '''\n",
    "NFL['ytg_bin'] = [yardage_bin(x) for x in NFL['ydstogo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5023f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Replace score differential values with bin numbers'''\n",
    "NFL['score_diff_bin'] = [score_diff_bin(x) for x in NFL['score_differential']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de6e6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Make yardline_100 and game_seconds_remaining on a scale of 0 to 1 '''\n",
    "NFL['yardline_100'] /= 100\n",
    "NFL['game_seconds_remaining'] /= 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7efc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' One hot encoding downs, ytg bins, cp_label, and score diff bins'''\n",
    "one_hot_downs = pd.get_dummies(NFL['down'], prefix='down')\n",
    "one_hot_ytg = pd.get_dummies(NFL['ytg_bin'], prefix='ytg_bin')\n",
    "one_hot_cpl = pd.get_dummies(NFL['cp_label'], prefix='cpl')\n",
    "one_hot_sd = pd.get_dummies(NFL['score_diff_bin'], prefix='score_diff_bin')\n",
    "one_hot_posteam = pd.get_dummies(NFL['posteam'], prefix = 'posteam')\n",
    "one_hot_posteam_type = pd.get_dummies(NFL['posteam_type'], prefix = 'posteam_type')\n",
    "one_hot_defteam = pd.get_dummies(NFL['defteam'], prefix = 'defteam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a8738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Add one hot values to DF '''\n",
    "NFL = pd.concat([NFL, one_hot_downs, one_hot_posteam,\n",
    "                 one_hot_posteam_type, one_hot_defteam,\n",
    "                 one_hot_ytg, one_hot_cpl, one_hot_sd], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef4f54",
   "metadata": {},
   "source": [
    "# Split the data up between input features, targets, and then train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "238079e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = NFL[['game_seconds_remaining', 'yardline_100', 'down_1.0', 'down_2.0', 'down_3.0', 'down_4.0', 'ytg_bin_0',\n",
    "         'ytg_bin_1', 'ytg_bin_2', 'ytg_bin_3', 'cpl_0', 'cpl_1', 'cpl_2', 'cpl_3', 'cpl_4', 'cpl_5', 'cpl_6', 'cpl_7',\n",
    "         'cpl_8', 'cpl_9', 'cpl_10', 'cpl_11', 'cpl_12', 'score_diff_bin_-4', 'score_diff_bin_-3', 'score_diff_bin_-2',\n",
    "         'score_diff_bin_-1', 'score_diff_bin_0', 'score_diff_bin_1', 'score_diff_bin_2', 'score_diff_bin_3',\n",
    "         'score_diff_bin_4', 'posteam_ARI', 'posteam_ATL', 'posteam_BAL', 'posteam_BUF', 'posteam_CAR', 'posteam_CHI',\n",
    "         'posteam_CIN', 'posteam_CLE', 'posteam_DAL', 'posteam_DEN', 'posteam_DET', 'posteam_GB', 'posteam_HOU',\n",
    "         'posteam_IND', 'posteam_JAC', 'posteam_JAX', 'posteam_KC', 'posteam_LA', 'posteam_LAC', 'posteam_MIA',\n",
    "         'posteam_MIN', 'posteam_NE', 'posteam_NO', 'posteam_NYG', 'posteam_NYJ', 'posteam_OAK', 'posteam_PHI',\n",
    "         'posteam_PIT', 'posteam_SD', 'posteam_SEA', 'posteam_SF', 'posteam_STL', 'posteam_TB', 'posteam_TEN',\n",
    "         'posteam_WAS', 'posteam_type_away', 'posteam_type_home', 'defteam_ARI', 'defteam_ATL', 'defteam_BAL',\n",
    "         'defteam_BUF', 'defteam_CAR', 'defteam_CHI', 'defteam_CIN', 'defteam_CLE', 'defteam_DAL', 'defteam_DEN',\n",
    "         'defteam_DET', 'defteam_GB', 'defteam_HOU', 'defteam_IND', 'defteam_JAC', 'defteam_JAX', 'defteam_KC', \n",
    "         'defteam_LA', 'defteam_LAC', 'defteam_MIA', 'defteam_MIN', 'defteam_NE', 'defteam_NO', 'defteam_NYG', 'defteam_NYJ',\n",
    "         'defteam_OAK', 'defteam_PHI', 'defteam_PIT', 'defteam_SD', 'defteam_SEA', 'defteam_SF', 'defteam_STL', \n",
    "         'defteam_TB', 'defteam_TEN', 'defteam_WAS']]\n",
    "\n",
    "y = NFL['play_success']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a28ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e91f11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree():\n",
    "    DT = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "    DT.fit(train_x, train_y)\n",
    "    predictions = DT.predict(test_x)\n",
    "    DTscore = accuracy_score(test_y, predictions)\n",
    "    print(\"Accuracy using Decision Tree: \" + str(DTscore))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65fdc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    RF = RandomForestClassifier(max_depth=10, n_estimators=25, random_state=1)\n",
    "    RF.fit(train_x, train_y)\n",
    "    predictions = RF.predict(test_x)\n",
    "    RFscore = accuracy_score(test_y, predictions)\n",
    "    print(\"Accuracy using Random Forest: \" + str(RFscore))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f07f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor():\n",
    "    knc = KNeighborsClassifier(n_neighbors=3)\n",
    "    knc.fit(train_x, train_y)\n",
    "    predictions = knc.predict(test_x)\n",
    "    knscore = accuracy_score(test_y, predictions)\n",
    "    print(\"Accuracy using k-Nearest Neighbors: \" + str(knscore))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce26b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    nn = MLPClassifier(verbose=True, random_state=1, early_stopping=True, max_iter=300)\n",
    "    nn.fit(train_x, train_y)\n",
    "    predictions = nn.predict(test_x)\n",
    "    nnScore = accuracy_score(test_y, predictions)\n",
    "    print(\"Accuracy using Neural Network: \" + str(nnScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b84602",
   "metadata": {},
   "source": [
    "# PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8db071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 104\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19bed7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, you can proceed to use it\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    # CUDA is not available, use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af4fa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_NFL = NFL[['game_seconds_remaining', 'yardline_100', 'down_1.0', 'down_2.0', 'down_3.0', 'down_4.0', 'ytg_bin_0',\n",
    "         'ytg_bin_1', 'ytg_bin_2', 'ytg_bin_3', 'cpl_0', 'cpl_1', 'cpl_2', 'cpl_3', 'cpl_4', 'cpl_5', 'cpl_6', 'cpl_7',\n",
    "         'cpl_8', 'cpl_9', 'cpl_10', 'cpl_11', 'cpl_12', 'score_diff_bin_-4', 'score_diff_bin_-3', 'score_diff_bin_-2',\n",
    "         'score_diff_bin_-1', 'score_diff_bin_0', 'score_diff_bin_1', 'score_diff_bin_2', 'score_diff_bin_3',\n",
    "         'score_diff_bin_4', 'posteam_ARI', 'posteam_ATL', 'posteam_BAL', 'posteam_BUF', 'posteam_CAR', 'posteam_CHI',\n",
    "         'posteam_CIN', 'posteam_CLE', 'posteam_DAL', 'posteam_DEN', 'posteam_DET', 'posteam_GB', 'posteam_HOU',\n",
    "         'posteam_IND', 'posteam_JAC', 'posteam_JAX', 'posteam_KC', 'posteam_LA', 'posteam_LAC', 'posteam_MIA',\n",
    "         'posteam_MIN', 'posteam_NE', 'posteam_NO', 'posteam_NYG', 'posteam_NYJ', 'posteam_OAK', 'posteam_PHI',\n",
    "         'posteam_PIT', 'posteam_SD', 'posteam_SEA', 'posteam_SF', 'posteam_STL', 'posteam_TB', 'posteam_TEN',\n",
    "         'posteam_WAS', 'posteam_type_away', 'posteam_type_home', 'defteam_ARI', 'defteam_ATL', 'defteam_BAL',\n",
    "         'defteam_BUF', 'defteam_CAR', 'defteam_CHI', 'defteam_CIN', 'defteam_CLE', 'defteam_DAL', 'defteam_DEN',\n",
    "         'defteam_DET', 'defteam_GB', 'defteam_HOU', 'defteam_IND', 'defteam_JAC', 'defteam_JAX', 'defteam_KC', \n",
    "         'defteam_LA', 'defteam_LAC', 'defteam_MIA', 'defteam_MIN', 'defteam_NE', 'defteam_NO', 'defteam_NYG', 'defteam_NYJ',\n",
    "         'defteam_OAK', 'defteam_PHI', 'defteam_PIT', 'defteam_SD', 'defteam_SEA', 'defteam_SF', 'defteam_STL', \n",
    "         'defteam_TB', 'defteam_TEN', 'defteam_WAS', 'play_success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8990f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train, torch_test = train_test_split(torch_NFL, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14f380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFL_Data(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform = transforms.ToTensor()):\n",
    "        self.data = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        \n",
    "        features = sample.iloc[:-1].values\n",
    "        target = sample.iloc[-1]\n",
    "        \n",
    "        features = np.array(list(features))\n",
    "        target = np.array(target)\n",
    "        \n",
    "        #print(\"Features: \", type(features))\n",
    "        #print(\"Target data type: \", type(target))\n",
    "        \n",
    "        features = torch.tensor(features)\n",
    "        target = torch.tensor(target)\n",
    "        #if self.transform:\n",
    "            #features = self.transform(features)\n",
    "            \n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81625abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NFL_Data(torch_test)\n",
    "test_dataset = NFL_Data(torch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f42b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77f2a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PlayPredictor, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 84)\n",
    "        self.linear2 = nn.Linear(84, 48)\n",
    "        self.linear3 = nn.Linear(48, 32)\n",
    "        self.linear4 = nn.Linear(32, 16)\n",
    "        self.linear5 = nn.Linear(16, 3)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        leaky_relu = nn.LeakyReLU(negative_slope=0.1)\n",
    "        x = leaky_relu(self.linear1(x))\n",
    "        x = leaky_relu(self.linear2(x))\n",
    "        x = leaky_relu(self.linear3(x))\n",
    "        x = leaky_relu(self.linear4(x))\n",
    "        x = self.linear5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9205504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, test_loader, model_name=\"Torch-Play-Success\", save_dir=\"model\"):\n",
    "    model = PlayPredictor(input_size, num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "\n",
    "    # If there is no save directory yet, make one\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    #outer training loop goes through all training data 5 times (num_epochs)\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        for step, (features, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            features = features.view(-1, input_size).float()\n",
    "\n",
    "            #zero out the gradient before each batch is processed\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #pass the batch of images through the model and collect the outputs\n",
    "            #outputs is 100 x 10 \n",
    "            outputs = model(features)\n",
    "\n",
    "            #calculate the loss for the mini-batch using the model-predicted scores over labels\n",
    "            #and the known labels; labels is a tensor of size 100\n",
    "            train_loss = criterion(outputs, labels.to(torch.long))\n",
    "\n",
    "            #propogate the loss backwards through the network\n",
    "            train_loss.backward()\n",
    "\n",
    "            #take a step with the optimzer to update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            #progress report\n",
    "            if (step) % 50 == 0:\n",
    "                \n",
    "                # Take model's predictions on training set\n",
    "                # Calculate its accuracy on training set\n",
    "                train_correct = 0\n",
    "                train_total = 0\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum()\n",
    "                train_acc = (100 * (train_correct/train_total))\n",
    "                train_acc = train_acc.item()\n",
    "                \n",
    "                # Now test the model on the test set, get the test accuracy and test loss\n",
    "                accuracy, test_loss = test(model=model, test_loader=test_loader, loss_func=criterion)\n",
    "\n",
    "                # Show the results\n",
    "                print('Epoch[{}]:Step[{}] Train Loss: {:.2f}\\tTrain Acc: {:.2f}%\\tTest Loss: {:.2f}\\t\\tTest Acc: {:.2f}%'.format(\n",
    "                    epoch, step, train_loss, train_acc, test_loss, accuracy))\n",
    "                save_model(model, model_name, accuracy)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6996db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model=None, test_image=None, test_loader=None, loss_func=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            \n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "\n",
    "            inputs = inputs.view(-1, input_size)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            test_loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Increment total number of observations seen by\n",
    "            # number of items in this batch\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Increment total number of correct predictions by\n",
    "            # number of correct predictions in this batch\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        accuracy = (100 * (correct/total))\n",
    "        accuracy = accuracy.item()\n",
    "        return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "412dfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_highest_accuracy(accuracy):\n",
    "    with open(\"highest_accuracy.txt\", \"w\") as f:\n",
    "        f.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "218ef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, accuracy):\n",
    "\n",
    "    highest_accuracy = load_highest_accuracy()\n",
    "\n",
    "    # Only save the model if its accuracy is higher than the previous model's\n",
    "    if accuracy > highest_accuracy:\n",
    "\n",
    "        save_highest_accuracy(accuracy)\n",
    "\n",
    "        file_path = \"./model/{}.pt\".format(model_name)\n",
    "\n",
    "        print(\"New highest accuracy. Saving model ...\")\n",
    "        print()\n",
    "\n",
    "        torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45901e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_highest_accuracy():\n",
    "    if os.path.exists(\"highest_accuracy.txt\"):\n",
    "        with open(\"highest_accuracy.txt\", \"r\") as f:\n",
    "            return float(f.read())\n",
    "    else:\n",
    "        return 0.0  # Default to 0.0 if the file doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6a27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d52ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdaac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
